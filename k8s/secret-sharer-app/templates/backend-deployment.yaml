# templates/backend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "secret-sharer-app.fullname" . }}-backend
  labels:
    {{- include "secret-sharer-app.labels" . | nindent 4 }}
    app.kubernetes.io/component: backend
spec:
  replicas: {{ .Values.backend.replicaCount | default 1 }}
  selector:
    matchLabels:
      {{- include "secret-sharer-app.selectorLabels" . | nindent 6 }}
      app.kubernetes.io/component: backend
  template:
    metadata:
      labels:
        {{- include "secret-sharer-app.selectorLabels" . | nindent 8 }}
        app.kubernetes.io/component: backend
    spec:
      serviceAccountName: {{ .Values.backend.serviceAccount.name }}
      automountServiceAccountToken: true # Required for Workload Identity if SA is specified
      containers:
        - name: backend
          image: "{{ .Values.acrLoginServer }}/{{ .Values.backend.image.name }}:{{ .Values.backend.image.tag | default .Chart.AppVersion }}"
          imagePullPolicy: {{ .Values.backend.image.pullPolicy | default "IfNotPresent" }}
          command: ["/bin/sh", "-c"]
          args:
            - |
              echo "Backend container starting. Waiting 5 seconds for network/DNS to stabilize further..."
              sleep 5
              echo "Starting Flask application..."
              exec flask run --host=0.0.0.0 --port={{ .Values.backend.service.port }}
          ports:
            - name: http
              containerPort: {{ .Values.backend.service.port }} # Assuming backend runs on port 5000 internally
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /health # Or your specific health check endpoint e.g., /health2
              port: http # Refers to the containerPort named 'http' (e.g., 8000)
            initialDelaySeconds: {{ .Values.backend.probes.liveness.initialDelaySeconds | default 15 }}
            periodSeconds: {{ .Values.backend.probes.liveness.periodSeconds | default 20 }}
            timeoutSeconds: {{ .Values.backend.probes.liveness.timeoutSeconds | default 5 }}
            failureThreshold: {{ .Values.backend.probes.liveness.failureThreshold | default 3 }}
            successThreshold: {{ .Values.backend.probes.liveness.successThreshold | default 1 }}
          readinessProbe:
            httpGet:
              path: /health # Or your specific health check endpoint e.g., /healthz
              port: http # Refers to the containerPort named 'http'
            initialDelaySeconds: {{ .Values.backend.probes.readiness.initialDelaySeconds | default 5 }}
            periodSeconds: {{ .Values.backend.probes.readiness.periodSeconds | default 10 }}
            timeoutSeconds: {{ .Values.backend.probes.readiness.timeoutSeconds | default 5 }}
            failureThreshold: {{ .Values.backend.probes.readiness.failureThreshold | default 3 }}
            successThreshold: {{ .Values.backend.probes.readiness.successThreshold | default 1 }}
          resources:
            limits:
              cpu: {{ .Values.backend.resources.limits.cpu | default "500m" }} # 0.5 CPU core
              memory: {{ .Values.backend.resources.limits.memory | default "256Mi" }}
            requests:
              cpu: {{ .Values.backend.resources.requests.cpu | default "100m" }} # 0.1 CPU core
              memory: {{ .Values.backend.resources.requests.memory | default "128Mi" }}
          env:
            # These will be populated from the Kubernetes secret created by the SecretProviderClass
            - name: MASTER_ENCRYPTION_KEY
              valueFrom:
                secretKeyRef:
                  name: {{ include "secret-sharer-app.fullname" . }}-backend-secrets
                  key: appMasterEncryptionKey # Key name within the K8s Secret
            - name: DATABASE_USER
              valueFrom:
                secretKeyRef:
                  name: {{ include "secret-sharer-app.fullname" . }}-backend-secrets
                  key: dbUser # Key name within the K8s Secret
            - name: DATABASE_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: {{ include "secret-sharer-app.fullname" . }}-backend-secrets
                  key: dbPassword # Key name within the K8s Secret
            - name: DATABASE_NAME
              value: {{ .Values.database.auth.database | quote }} # From database values
            - name: DATABASE_HOST
              value: {{ include "secret-sharer-app.fullname" . }}-db-headless
            - name: DATABASE_PORT
              value: "5432" # Default PostgreSQL port
            # Your Python app will need to construct the DATABASE_URL from these individual components
            # Alternatively, the SecretProviderClass could create a secret with a fully formed DATABASE_URL if preferred.

          # We will add livenessProbe and readinessProbe later
          # We will add resources (requests/limits) later
          volumeMounts:
            - name: secrets-store-inline
              mountPath: "/mnt/secrets-store" # Secrets will be mounted here as files by CSI driver
              readOnly: true
      initContainers:
        - name: wait-for-db
          image: busybox:1.36
          command: ['sh', '-c', 'until nc -z {{ include "secret-sharer-app.fullname" . }}-db-headless 5432; do echo waiting for db; sleep 30; done']
      volumes:
        - name: secrets-store-inline
          csi:
            driver: secrets-store.csi.k8s.io
            readOnly: true
            volumeAttributes:
              secretProviderClass: {{ include "secret-sharer-app.fullname" . }}-backend-spc
            # nodePublishSecretRef: # Only needed if Azure Key Vault firewall is enabled for specific service endpoints
            #   name: ""